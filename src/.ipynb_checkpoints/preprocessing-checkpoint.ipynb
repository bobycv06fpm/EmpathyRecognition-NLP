{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_no_emo_data(file_path):\n",
    "    chats = []\n",
    "    for line in open(file_path, 'r'):\n",
    "        chats.append(json.loads(line))\n",
    "    data = []\n",
    "    for chat in chats:\n",
    "        for text in chat['dialogue']:\n",
    "            if text['emotion'] == 'no_emotion':\n",
    "                data.append(text['text'])\n",
    "    return data\n",
    "\n",
    "def get_empathy_data(file_path):\n",
    "    data = pd.read_csv(file_path,error_bad_lines=False)\n",
    "    data = list(data[['conv_id','prompt']].groupby(\"conv_id\").agg('max')['prompt'])\n",
    "    data = list(map(lambda x: x.replace('_comma_',' ,'),data))\n",
    "    return data\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../data/dailydialog/train.json'\n",
    "val_path = '../data/dailydialog/valid.json'\n",
    "test_path = '../data/dailydialog/test.json'\n",
    "no_emo_data = get_no_emo_data(train_path) + get_no_emo_data(val_path) + get_no_emo_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empathy_train_path = \"../data/empatheticdialogues/train.csv\"\n",
    "empathy_valid_path = \"../data/empatheticdialogues/valid.csv\"\n",
    "empathy_test_path = \"../data/empatheticdialogues/test.csv\"\n",
    "empathy_data = get_empathy_data(empathy_train_path)+get_empathy_data(empathy_valid_path)+get_empathy_data(empathy_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_emo_data_sampled = random.sample(no_emo_data,len(empathy_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_emo_label = [0]*len(empathy_data)\n",
    "empathy_label = [1]*len(empathy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = no_emo_data_sampled + empathy_data\n",
    "label = no_emo_label + empathy_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data, label, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33327.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)*0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(x_train,open( \"../data/x_train.p\", \"wb\" ))\n",
    "pickle.dump(y_train,open( \"../data/y_train.p\", \"wb\" ))\n",
    "pickle.dump(x_test,open( \"../data/x_test.p\", \"wb\" ))\n",
    "pickle.dump(y_test,open( \"../data/y_test.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pickle.load(open( \"../data/x_train.p\", \"rb\" ))\n",
    "y = pickle.load(open( \"../data/y_train.p\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39344"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
